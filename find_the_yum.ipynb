{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaoCuii/Calculator-11/blob/main/find_the_yum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyPaFDPHD0rB",
        "outputId": "aee40be5-7955-4c65-ec08-223290b0509a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOF82iIAXhbv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import os, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.applications import VGG16\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image_dataset_from_directory\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='magma')\n",
        "\n",
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FRUIT DATA CREATING CSV\n"
      ],
      "metadata": {
        "id": "imX2S2IYBZdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_train = []\n",
        "labels_train = []\n",
        "\n",
        "for i in range(len(train_filenames)):\n",
        "    try:\n",
        "      img_name = train_filenames[i]\n",
        "      label = train_categories[i]\n",
        "\n",
        "      image = Image.open(img_name).convert('RGB')\n",
        "      image = image.resize((224,224))\n",
        "      image_array = np.array(image)\n",
        "\n",
        "      images_train.append(image_array)\n",
        "      labels_train.append(label)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "np_images_train = np.array(images_train)\n",
        "np_labels_train = np.array(labels_train)\n"
      ],
      "metadata": {
        "id": "AJ4k_HyjYXAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "np_images_train = np_images_train.reshape(np_images_train.shape[0], -1)\n",
        "X_train = pd.DataFrame(np_images_train)\n",
        "\n",
        "np_labels_train = np_labels_train.reshape(np_labels_train.shape[0], -1)\n",
        "y_train = pd.DataFrame(np_labels_train)\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
        "\n",
        "\n",
        "'''np_images_test = np_images_test.reshape(np_images_test.shape[0], -1)\n",
        "X_test = pd.DataFrame(np_images_test)\n",
        "\n",
        "np_labels_test = np_labels_test.reshape(np_labels_test.shape[0], -1)\n",
        "y_test = pd.DataFrame(np_labels_test)\n",
        "\n",
        "X_test, y_test = shuffle(X, y, random_state=42)'''"
      ],
      "metadata": {
        "id": "FIOu1STyP3IN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded_train = label_encoder.fit_transform(y_train.values.ravel())  # Ensure y is 1D\n",
        "'''y_encoded_test = label_encoder.fit_transform(y_test.values.ravel())  # Ensure y is 1D'''"
      ],
      "metadata": {
        "id": "EY2Hka_YXtyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = X_train.shape[0]  # Number of samples\n",
        "height = 224  # Original height of images\n",
        "width = 224   # Original width of images\n",
        "channels = 3  # Number of channels (e.g., 3 for RGB)\n",
        "\n",
        "# Reshape the flattened images back to 3D shape\n",
        "X_reshaped_train = X_train.values.reshape(batch_size, height, width, channels)\n",
        "\n",
        "# Now you can resize the images\n",
        "X_resized_train = tf.image.resize(X_reshaped_train, (224, 224))\n",
        "X_resized_train = X_resized_train.numpy().astype('float32')  # Ensure dtype is float32\n",
        "# Normalize pixel values to [0, 1]\n",
        "X_resized_train = X_resized_train / 255.0\n",
        "\n",
        "# Now X_resized is ready for training or prediction\n",
        "print(X_resized_train.shape)  # Should print (batch_size, 224, 224, 3)\n",
        "\n",
        "X_train = X_resized_train\n",
        "\n",
        "'''\n",
        "batch_size = X_test.shape[0]  # Number of samples\n",
        "\n",
        "X_resized_test = X_test.values.reshape(batch_size, height, width, channels)\n",
        "X_resized_test = tf.image.resize(X_resized_test, (224, 224))\n",
        "X_resized_test = X_resized_test.numpy().astype('float32')\n",
        "X_resized_test = X_resized_test / 255.0\n",
        "\n",
        "X_test = X_resized_test'''"
      ],
      "metadata": {
        "id": "Ca9M9fhgSGog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "model = keras.Sequential([\n",
        "    #base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.BatchNormalization(input_shape=(X_train.shape[1],)),\n",
        "\n",
        "    layers.Dense(1024, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(len(label_encoder.classes_), activation='softmax'),  # Matches # classes\n",
        "])"
      ],
      "metadata": {
        "id": "oxFZoBG-_NRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    restore_best_weights=True,\n",
        ")"
      ],
      "metadata": {
        "id": "0Jv6MLbw_So9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
        "    loss='sparse_categorical_crossentropy',  # Integer labels\n",
        "    metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "yiTzpOVL_Tjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    #validation_data=(), ########################################## CHANGE HERE\n",
        "    batch_size=128,  # Smaller batch size\n",
        "    epochs=256,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-Entropy Loss\")\n",
        "history_df.loc[:, ['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")"
      ],
      "metadata": {
        "id": "DRdBM9qW2ISs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the image and preprocess\n",
        "img_path = \"/content/drive/My Drive/regen_fruit_dataset/train/Banana/img_1371.jpeg\"\n",
        "\n",
        "# Load the image (resize it to 128x128 as expected by the model)\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "# Add the batch dimension\n",
        "img_array = np.expand_dims(img_array, axis=0)  # This will change the shape to (1, 128, 128, 3)\n",
        "\n",
        "# Normalize the image if needed (based on how you processed it during training)\n",
        "img_array = img_array / 255.0  # If you scaled during training\n",
        "\n",
        "# Now you can use this img_array to make predictions\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# If you're doing classification, find the class with the highest probability\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "\n",
        "# If you have the list of labels for classes\n",
        "fruit_categories = [\n",
        "    'Apple',\n",
        "    'Banana',\n",
        "    'avocado',\n",
        "    'cherry',\n",
        "    'kiwi',\n",
        "    'mango',\n",
        "    'orange',\n",
        "    'pinenapple',\n",
        "    'strawberries',\n",
        "    'watermelon']\n",
        "predicted_label = fruit_categories[predicted_class[0]]\n",
        "\n",
        "print(f\"Predicted class: {predicted_label}\")\n"
      ],
      "metadata": {
        "id": "YgFVQLXEVp9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CWTPU-C0gy6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('ReGen_CNN.keras')"
      ],
      "metadata": {
        "id": "vBQ9TLd3fSUf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}